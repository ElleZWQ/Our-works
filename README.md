# Our-works
This repository includes our work on causal discovery and domain adaptation/domain generalization.
Welcome everyone to come to join us (Especially for students conducting independent research,) and learn about our work.

## Causal discovery

1. [Causality Detection with Matrix-based Transfer Entropy](https://www.sciencedirect.com/science/article/pii/S0020025522010830)
   - Published in Information Sciences (SCI, top journal, 中科院一区, 西交最具)
   - [Code](https://github.com/zwq2/MTE_causal.git)
   - Contributions: propose two novel matrix-based estimators for conditional transfer entropy and high-order transfer entropy.
     The former can detect both indirect and common causation, while the latter can detect synergistic effect. 
2. [Jacobian Regularizer-based Neural Granger Causality](https://openreview.net/forum?id=FG5hjRBtpm)
   - Published in ICML 2024 (CCFA, top AI conference, 西交最具)
   - [Code](https://github.com/ElleZWQ/JRNGC.git)
   - Contributions: To our best knowledge, this is the first work to harness a single NN model with shared hidden layers for multivariate Granger causality analysis. Our method can not only obtain the summary Granger causality but also the full-time Granger causality. We evaluate our method on commonly used benchmark datasets with extensive experiments. Our method can
outperform state-of-the-art baselines and show an excellent ability to discover Granger causality, especially for sparse causality.
3. [An Information-Theoretic Approach for Heterogeneous Differentiable Causal Discovery](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4837242)
   - Under review
   - Code will be published in this GitHub account.
   - Contributions: To this end, we introduce a novel information-theoretic approach designed to enhance the robustness of differential causal discovery methods. Theoretically, we demonstrate that our approach leverages the structural identifiability characteristic inherent in existing causal discovery methods for linear systems. Furthermore, we explore how the MEE
enhances the reliability and robustness of causal inference by evenly distributing prediction errors across diverse samples.

## Domain Adaption/Generalization

1. [Prompt-based distribution alignment for unsupervised domain adaptation](https://ojs.aaai.org/index.php/AAAI/article/view/27830)
   - Published in AAAI 2024 (CCF A, 西交最具)
   - [Code](https://github.com/BaiShuanghao/Prompt-based-Distribution-Alignment.git)
   - Contributions: We first experimentally verify the effectiveness of VLM on UDA downstream tasks. Then, based on this finding, we further propose a prompt-based distribution alignment (PDA) method to tune prompt to the target domain. The proposed PDA includes two training branches. First, the base branch ensures discrimination among different
classes. Second, the aligned branch obtains the domain invariant information by image-guided feature tuning.

2. [Soft Prompt Generation for Domain Generalization](https://arxiv.org/abs/2404.19286)
   - Accepted by ECCV 2024 (CCF B, top Computer Vision Conference, 西交最具)
   - [Code](https://github.com/renytek13/Soft-Prompt-Generation.git)
   - Contributions: We propose a prompt-based domain generalization method from a generative perspective.

### Under Review
We have two papers about domain generalization.
   -  ICASSP Submitted. [PromptTA: Prompt-driven Text Adapter for Source-free Domain Generalization](https://arxiv.org/abs/2409.14163)
      - [Code] (https://github.com/zhanghr2001/PromptTA.git).
     

Other work can be seen in [Google Scholar](https://scholar.google.com/citations?user=3Q_3PR8AAAAJ&hl=zh-CN).
  


